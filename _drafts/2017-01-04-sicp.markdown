---
layout: post
title: "SICP"
date: 2017-01-04 20:02
comments: true
categories: [clojure, programming, fp, book]
sharing: true
published: true
mathjax: true
---

It was my third attempt to read one of hardest and most influential computer science book: [Structure and Interpretation of Computer Programs](https://mitpress.mit.edu/sicp/full-text/book/book.html) (**SICP**) by Abelson and Sussman.

Fortunately, attempt was succesful and here is my "structure and interpretation" of this book.

<!-- more -->

# 1. Building Abstractions with Procedures

Abstract beings that inhabit computers called **computational processes**.  
As they evolve they manipulate other abstract things called **data**.  
The evolution of a process directed by rules called a **program**.  
People use **programming languages** to create **programs**.  

## 1.1 The Elements of Programming

Every _powerful_ programming language consists of three mechanisms:  

- **primitive expressions**, which represent the simplest entities.
- **means of combination**, by which compound elements are built from simpler ones.
- **means of abstraction**, by which compound elements can be named and manipulated as units.

In programming we deal with two kinds of elements: **programs** and **data** (Later we will discover that they are really not so distinct)

### 1.1.1 Expressions

Lisp interpreter called REPL, read-eval-print loop. First, it **reads** input from user, then **evaluates** input, by applying various rules and lastly **prints** result back to user. All these three actions done in a **loop**.

For example, if you type in REPL expression `486` it will be evaluated and prints back `486`. This is a primitive expression.  
Using combination rules you can create a complex expressions, like `(+ 137 349)`. If you send this expression to REPL, it will evaluate to `486` as well. But in that case, REPL was treating this expression as an operator `+` called with arguments `137` and `349`. So, basically, it performs mathematical addition

The convention of placing operator before arguments called **prefix notation** and can be confusing, because in math we used to write `2+3` instead of `(+ 2 3)`. In fact, prefix notation has several advantages:

- You can define `+` as a vararg function and write  
  `(+ 23 45 6 7 89)` instead of `23 + 45 + 6 + 7 + 89`
- Most probably, when you call a regular function in your language you already using prefix notation `object.send(message, sender, format)`, Lisp just treats math operators as functions.
- You can use naturally nested expressions and forget about math prioritites and other confusions  
  `(+ (* 2 5) (- 100 (/ 36 6)))` 

Remember, if you see a list expression, like `(+ 1 2)`, first element `+` is a function, and other elements `2` and `3` are arguments.

### 1.1.2 Naming and the Environment

By the simplest mean of abstraction, you can associate expression with some name and use already associated names in other expressions.

```clojure
(def pi 3.14159)
(def radius 10)
(def circumference (* 2 pi radius))
```

All names are stored as list of `<name,expression>` pairs in a place called the **environment**.

### 1.1.3 Evaluating Combinations

To evaluate compound expression, interpreter does the following:

- Evaluate all subexpressions
- Apply function (which is leftmost element in the list) to operands.

You can see the evaluation nature of interpreter is **recursive**.

For example, to evaluate expression `(* (+ 2 (* 4 6)) (+ 3 5 7))`, interpreter need to apply function `*` to value of expressions `(+ 2 (* 4 6))` and `(+ 3 5 7)`. To get those values, it needs to evaluate them as well until simplest expression will be obtained.

Better to view this evaluation process as a tree:

<img src="/images/sicp/1.1.3_tree.png" alt="Tree" style="width: 300px;"/>

This is the simplest and most used evaluation rule in interpreter.

Note, that naming expressions, like `(def a 3)` are not regular expressions, but called **special forms** instead, their evaluation has other rules. A set of such exceptions from general evaluation rule, called **syntax** of programming language.

Special syntactic forms that are simply convenient alternative for things that can be written in more uniform ways are called **syntactic sugar**. Programming languages with lot of "syntactic sugar" constructions harder to understand and they causing more troubles when program become large and complex. In the words of Alan Perlis:

> Syntactic sugar causes cancer of the semicolon

### 1.1.4 Compound Procedures

By one of abstraction rules we can give names to the expressions, an refer to this expression just using names, `(def pi 3.14)`

Another important abstraction structure is giving name to custom functions. We begin by examining how to express the idea of "squaring". We might say, _"To square something, multiply it by itself"_. In Clojure it looks like:

``` clojure
(defn   square  [x]        (*       x     x))
;; ^    ^        ^         ^        ^     ^
;; to   square   something multiply it by itself
```

Later, in a program you can use name `square` to square something.

``` clojure
(square 2)  ;; => 4
(square 12) ;; => 144
```

Even more, you can use name `square` to refer to this function as building block for other functions. For example the function which calculates sum of squares $x^2 + y^2$ look like this:

``` clojure
(defn sum-of-squares [x y]
  (+ (square x) (square y)))
```

### 1.1.5 The Substitution Model for Procedure Application

To apply a compound procedure to arguments, evaluate the body of the procedure with each formal parameter replaced by the corresponding argument.

Let's demonstrate this process on the application `(sum-of-squares (+ 3 5) (* 10 2))`

``` clojure
;; Input
(sum-of-squares (+ 3 5) (* 10 2))
;; Evaluate arguments
(sum-of-squares 8 20)
;; Replace sum-of-squares with its definition
(+ (square 8) (square 20))
;; Replace square the same way
(+ (* 8 8) (* 20 20))
;; Now there are no compound procedures and interpreter
;; can evaluate it using general evaluation rule
(+ 64 400)
464
```

The process we just described is called **substitution model** for function application. This process uses evaluation strategy called **applicative-order evaluation**, because we _"evaluate the arguments and then apply"_. Another strategy called **normal-order evaluation** exists and this strategy is basically _"fully expand and then reduce"_. Let's demonstrate it on the same example:

``` clojure
;; Input
(sum-of-squares (+ 3 5) (* 10 2))
;; Replace sum-of-squares with its definition but DO NOT evaluate arguments
(+ (square (+ 3 5)) (square (* 10 2)))
;; Replace square the same way
(+ (* (+ 3 5) (+ 3 5) (* (* 10 2) (* 10 2))))
;; Now there are no compound procedures and interpreter
;; can evaluate it using general evaluation rule
(+ (* 8 8) (* 20 20))
(+ 64 400)
464
```

Result is the same, but process is different. We didn't evaluate arguments before substitution, that's why `square` produces two equal expressions, like `(+ 3 5)` and `(* 10 2)`, which will be evaluated twice and therefore total time of application is a bit larger.

On the other side, pros are not so explicit. For example, if you have arguments, which are not used in function definition, they won't be evaluated at all.

```clojure
(defn increment-first-argument [a b]
  (+ a 1))

(increment-first-argument 10 (+ 3 5)) ;; => 11

;; if normal-order evaluation used
(increment-first-argument 10 (+ 3 5))
(+ 10 1)
11

;; if applicative-order evaluation used
(increment-first-argument 10 (+ 3 5))
(increment-first-argument 10 8)
(+ 10 1)
11

;; You can see, applicative order did extra computation of
;; unneeded argument b (+ 3 5)
```

### 1.1.6 Conditional Expressions and Predicates

Conditional expressions allow branching logic in your program. The simplest conditional expression in Clojure is `cond`

```clojure
(def x 3)

(cond
  (< x 0) (+ x 1)
  (= x 0) (+ x 2)
  (> x 0) (+ x 3)
  true    0)
```

`cond` consists of pairs `<predicate, expression>`. **Predicate** is also an expression, which has a boolean value, true or false. Keep in mind that `cond` is not a function, it is a special form, so interpreter has specific rules to evaluate this form.

Interpreter evaluates first predicate `(< x 0)`, takes the value of `x` from the environment (which is 3), `(< 3 0)` yields false, so it _skips_ the expression associated with that predicate `(+ x 1)` and does not evaluate it at all. It continuosly evaluates all predicates until it reaches the predicate which value is true. In this case `(> 3 0)` returns true, so corresponding expression `(+ x 3)` will be evaluated.

If all predicates returned `false`, the value of `cond` is `nil` (special value to denote abscence of value)

There is also special form, called `if` which is similar to `cond`, but only for two branches.

```clojure
(if (> x 0) (+ x 3)   ;; if (> x 0) is true, (+ x 3) will be evaluated
            (+ x 2))  ;; otherwise (+ x 2) will be evaluated
```

There are also logical composition operators, such as `and`, `or`, `not`, which used to construct complex predicates.
Note, `and` and `or` are special forms as well, so interpreter doesn't evaluate all arguments.

```clojure
;; (and) stops evaluating if some predicate returns false
(and (> 10 3) (< 5 2) (> 7 9))

;; (> 10 3) => true, next expression
;; (< 5 2)  => false, stop evaluation and return false for the whole expression
;; Not evaluated: (> 7 9)

;; (or) stops evaluating if some predicate returns true
(or (> 10 3) (< 5 2) (> 7 9))
;; (> 10 3) => true, stop evaluation and return true for the whole expression
;; Not evaluated: (< 5 2), (> 7 9)
```

### 1.1.7 Example: Square Roots by Newtonâ€™s Method

Newton's Method provide numerical method for calculating square root $\sqrt{x}$

Having initial guess value $y$ we can improve it by averaging $y$ and $\frac{x}{y}$, so our next guess $y_{next} = \frac{(y_{prev} + \frac{x}{y_{prev}})}{2}$  
We continue improving our guess, until we satisfied with result, what means $y_{guess}^2 \approx x$  

Proximity of $y_{guess}$ to $\sqrt{x}$ will de defined as absolute difference between those values are less then some tolerance threshold

``` clojure
;; generic iterative algorithm which improves the guess
;; until it is good enough
(defn sqrt-iter [guess x]
  (if (good-enough? guess x)
    guess
    (sqrt-iter (improve guess x) x)))

;; good enough means absolute difference between squared guess
;; and x is less than provided tolerance 0.001
(defn good-enough? [guess x]
  (< (Math/abs (- (* guess guess) x))
     0.001))

;; improve uses Newton's formulae to get next guess, closed to real value
(defn improve [guess x]
  (/ (+ guess (/ x guess)) 2))

;; Just for conveniece, we provide function with initial guess 1.0
(defn sqrt [x]
  (sqrt-iter 1.0 x))

(sqrt 4) ;; => 2.0000000929222947
(sqrt 9) ;; => 3.00009155413138
```

The interesting part here is `sqrt-iter`, it demonstrates how iteration can be accomplished using no special construct other than the ordinary ability to call a procedure.

### 1.1.8 Procedures as Black-Box Abstractions

Based on previous `sqrt-iter` function we see how we can decompose our problem into smaller subproblems and solve each of them by separate function. Another important note is when we use external functions we treat them as black-box abstractions and only concerned **what** they do, and not focused on **how** they implemented.

For example, there are couple of ways to implement `square` function:

``` clojure
(defn square [x] (* x x))
(defn square [x] (Math/pow x 2))
(defn square [x] (exp (* 2 (log x))))
```

But, we only concerned on the function `square`, if it squares the number, we fine. Keep in mind, that local parameters for the function, if it `x` or `y` should not affect external program.

If function definition uses variable from argument list, it's called **bound** variable. If it uses variable from the environment, it's called **free** varible. Function arguments names exist only in functions body **scope**.

``` clojure
(def x 10) ;; x exists in global environment
(def y 20) ;; y exists in global environment

(defn some-function [x] ;; this x exists only in function scope
  (+ x y)
  ;; x is bound variable and equal to value which was passed to the function
  ;; y is free variable and always equal to y from external environment
  )
					
(some-function 1)   ;; => 21
(some-function 100) ;; => 120
x                   ;; => 10
```

Back to our `sqrt` function, we defined some helper functions, like `improve`, `good-enough?`, `sqrt-iter`, but they only make sense within `sqrt` context and not called directly. We can hide those function definitions inside `sqrt` definition using `let` block. (We will revisit it later, but `let` introduce local environment, where we can define things.

``` clojure
(defn sqrt [x]
  (let [improve (fn [guess] (/ (+ guess (/ x guess)) 2))
        good-enough? (fn [guess]
                       (< (Math/abs (- (* guess guess) x))
                          0.001))
        sqrt-iter (fn [guess]
                    (if (good-enough? guess)
                      guess
                      (sqrt-iter (improve guess x))))]
    (sqrt-iter 1.0)))
```

We just moved all definitions inside let block, inside `sqrt` function. But if you see closer, there is no `x` argument for internal functions definition, they can take `x` value from whatever provided to `sqrt` function. This way `x` become a _free_ variable and such trick is called **lexical scoping**.

## 1.2 Procedures and the Processes They Generate

> We have now considered the elements of programming: We have used primitive arithmetic operations, we have combined these operations, and we have abstracted these composite operations by defining them as compound procedures. But that is not enough to enable us to say that we know how to program. Our situation is analogous to that of someone who has learned the rules for how the pieces move in chess but knows nothing of typical openings, tactics, or strategy. Like the novice chess player, we donâ€™t yet know the common patterns of usage in the domain. We lack the knowledge of which moves are worth making (which procedures are worth defining). We lack the experience to predict the consequences of making a move (executing a procedure).

### 1.2.1 Linear Recursion and Iteration

Consider the simplest recursive implementation of `factorial` function:

``` clojure
(defn factorial [n]
  (if (= n 1)
      1
      (* n (factorial (- n 1)))))
```

This recursive process better describe with the figure

<img src="/images/sicp/1.2.1_recursion.png" alt="Recursion" style="width: 400px;"/>

We used substitution model to show how the process is expanding.
At each recursive call, result expression grows.
As we use only one recursive call each time, such process is called **linear recursive process**

Consider another implementation with accumulation of result.

``` clojure
(defn factorial [n]
 (let [fact-iter (fn [product counter]
                   (if (> counter n)
                       product
                       (recur (* counter product) (+ counter 1))))]
   (fact-iter 1 1)))
```

It also uses recursive calls, but the process tree looks different

<img src="/images/sicp/1.2.1_iteration.png" alt="Iteration" style="width: 300px;"/>

The difference is, recursive call is last expression in the definition, such recursive calls are optimized by compiler to iterative process and called **tail-call optimization** (TCO). Compilers with TCO do not need any special iteration constructions and can use ordinary function calls.

### 1.2.2 Tree Recursion

Another common pattern of computation is called **tree recursion**.  
Consider, the _fibonacci sequence_, where each number is sum of preceding two:

0, 1, 1, 2, 3, 5, 8, 13, ...

Formal definition will be following:

$$
fib(n) =
\begin{cases}
0, & \text{if $n = 0$} \\\\
1, & \text{if $n = 1$} \\\\
fib(n-1) + fib(n-2), & \text{otherwise}
\end{cases}
$$

And the straightforward implementation:

``` clojure
(defn fibonacci [n]
  (cond
    (= n 0) 0
    (= n 1) 1
    :else (+ (fibonacci (- n 1))
             (fibonacci (- n 2)))))
```

The recursion process, knows as **tree recursion** looks like this:

<img src="/images/sicp/1.2.2_fibonacci.png" alt="Fibonacci" style="width: 400px;"/>

Actually, it is a terrible way to calculate fibonacci numbers, because there are so many redundant computations.

Much better to express fibonacci sequence as _iterative process_. Start, as $fib(0)=0$, $fib(1)=1$ and iteratively apply transformations to produce next numbers: $a \leftarrow a + b$, $b \leftarrow a$

``` clojure
(defn fib [n]
  (let [fib-iter (fn [a b count]
                   (if (= count 0)
                     b
                     (recur (+ a b) a (- count 1))))]
    (fib-iter 1 0 n)))
```

One should not conclude from this that tree-recursive processes are useless. When we consider processes that operate on hierarchically structured data rather than numbers, we will find that tree recursion is a natural and powerful tool.

One way to avoid repeated computations is technique, called **memoization**

### 1.2.3 Order of Growth

TODO

### 1.2.4 Exponentiation
